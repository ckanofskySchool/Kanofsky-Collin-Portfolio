{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction Hi, my name is collin kanofsky and I am a senior at Charlotte Latin School looking ot major in mechatronics. Throughout my childhood, I have built numberous robots and machines through my super fun robotics teams and the intense but greatly benificial Fab Academy program. However, as I approached my senior year capstone project, I decided that I wanted to take my knowledge from robotics, and apply it with the skills from Fab Academy to make a modular Chassis that can host many projects to come. However, before I get ahead of myself, I am starting off with the goal of a backpack carrying robot I have named the \"Robopack\". This robot will carry around your backpack for you and will give me a starting point for future more intricate and advanced projects.","title":"Home"},{"location":"#introduction","text":"Hi, my name is collin kanofsky and I am a senior at Charlotte Latin School looking ot major in mechatronics. Throughout my childhood, I have built numberous robots and machines through my super fun robotics teams and the intense but greatly benificial Fab Academy program. However, as I approached my senior year capstone project, I decided that I wanted to take my knowledge from robotics, and apply it with the skills from Fab Academy to make a modular Chassis that can host many projects to come. However, before I get ahead of myself, I am starting off with the goal of a backpack carrying robot I have named the \"Robopack\". This robot will carry around your backpack for you and will give me a starting point for future more intricate and advanced projects.","title":"Introduction"},{"location":"DailyJournal/","text":"9/16/2025 Today, we learned about Git, Github, Github desktop, and the browser github as well. Specifically, we focused on how changes are stored in Git and the ability to create branches of the repo for development without affecting the original branch. 9/17/2025 Today, we practiced with Git and created shared Repo's with each other to practice with collaborator settings on github. 9/24/2025 Today, I decided to order the essential electronics for my project, this included the motor controllers, the batteries, and the safety mechanisms. 9/25/2025 Today, we did a soldering activity where we practiced surface mount and through hole soldering using a halloween owl kit which lights up when you touch it. The surface mount soldering, internal components, and the finished product are shown in pictures below. 9/26/2025 Outside of class today, I used the AI Claude with the Opus4.1 model to generate some starting code for my project. The programs I had made were a RP2040 Seeed program which will control the motors, and a RaspberryPi + AI Camera program which will hand the tracking aspects and math of the camera. I am using the AI formulated code as a launchpad in order to be more efficient and spend more time on customization and troubleshooting, than have to spend that time on writing the base code myself. However, to ensure I understood the code and would be able to edit and modify it, I made sure to go through each line and ensure that I understood why and what the line did, and how modifing that line of code would impact the overall preformance of the program. The initial prompts I inputed are shown below. Prompt for RP2040 Seeed Code write me an arduino code for a RP2040 Seeed which will take input from the usb serial coming off a raspberry pi and move 2 drive motors on my robot using pwm(like how servos are controlled) according to the directions. For input directions, there should be a heading which if is outside the middle range set by me in a variable, then the program should turn until the the heading is once again within acceptable values. Another input will be the distance from the target which also should be kept within acceptable range set by me in a variable. Lastly, have a serial monitor where I can input values for left motor and right motors to test if I want. One last thing is whenever motor powers are set, send back what has been set across the usb serial for the Pi to recieve. Prompt for Raspberry Pi Code can you now right me a raspberry pi program in pythong prob. that will provide these inputs needed based off a raspberry pi 5 and a raspberry pi AI camera attachment. Also have the raspberry pi host a webserver that allows the user to see the motor power assignements and camera feed. there should be a simple but neat UI for that web page pls. 10/6/2025 I have done some thinking and realized that I was going too big on the first code attempt, so I backtracked a bit back to the Raspberry Pi AI Camera Documentation, and completed the instructions as well as ran the example program: rpicam-hello -t 0s --post-process-file /usr/share/rpi-camera-assets/imx500_mobilenet_ssd.json --viewfinder-width 1920 --viewfinder-height 1080 --framerate 30 This program worked amazing and highlighted me with a bounding box as well as providing a percentage of certanty which seemed to stay above 50% consistantly. 10/7/2025 Layouts Today, I worked on the electrical for the robot, mainly trying to get power and control to 1 motor for testing. The layout of main power in my electrical testing setup went as such: Battery(12v 15000AmH) --> Breaker(30A) --> MotorController(Koors40 Brushed DC Motor Controller) --> Motor(CIM Motor) Then, I had to have a seperate control setup which would tell the motor controller how to move the motor. I also had to wire up a 5V power source into the receiver because the PWM output from the motor controller didn't provide a 5V port, just signal and ground wires. The layout of the control setup went as such: Controller(Wireless RC Plane Controller) --> Reciever(RC Plane Reciever) --> MotorControllerPWM(Koors40 Brushed DC Motor Controller) I haven't built this part yet because I chose to focus on the main power layout. Making Connections The main focus I had when setting up the hardware was modularity. I want to be able to replace components if I need to, or swap them out wihtout having to unsolder or cut wires, so I decided to use Wago connectors which take to unsoldered raw wire ends, and clamp down a metal plate on the wires forming a connection between the wires on both sides. These connectors worked great, but I sadly only snagged 2 from my robotics team, and I inevitablly ended up needing 4, so I put the final wiring on hold until I could get some more Wago connectors. I also had to do some soldering to 10/8/2025 Today, I found the github repo for the rpicam-hello program and ran it as a python file which allowed me to make edits to the code itself. I then used the AI ChatGPT from OpenAI to add in code for outputing where the human is in the serial terminal. I chose to use ChatGPT because Claude didn't seem great at modifing the codes without re-writing everything and that would always end up casuing errors. ChatGPT had me edit one of the functions and everything else stayed the same so when I tested the new code, it worked great and I was able to route the output to my computer terminal temporarily, so I could see the output without another device on the other side of the serial connection. Here is the original code: rpicam-hello Here is the updated code which I developed with AI assistance: modified rpicam-hello This code worked amazing and had very simular functions to the example, but a few key modifications to make it more effective and accurate for my use: - Added a stabalizing function - The data would update every frame and the bounding box would move after every update, still correct, but I don't need that much precision of 5 pixel shift to the left or whatever, so I insterted a snipet of code which only changes the detection bounding box if the center point has moved by >25 pixels, or the size has changed by 20%. This helped smooth the detection and give a more stable instruction which will be easier for the robot to follow. Added output to Serial for the Seeed board to receive instructions In order to tell the Seeed board where the person is, I outputed a formated set of data which gives the centerpoint x and y position, as well as the width and height of the bounding box. The format goes like such: x,y,w,l By changing the serial port from 3 to 1, which is the computers port, I was able to visualize the output on the terminal and confirm that the code was working correctly. Video of the Code Functioning 10/9/2025 Today, I continued working on the electrical testing setup I started on 10/7/2025. I acquired 4 more Wago connectors from my robotics team and finished up the connections between the motor and the motor controller using them. After finishing the main power setup, I started building the control wiring setup. I used a 5V power supply to power a remote control plane reciever which outputs a pwm signal, used to control the motor. Then I attached the pwm signal and ground to the reciever on the throttle port of the reciever and was able to control the motor using a RC Plane Remote. Video of motor moving","title":"Daily Journal"},{"location":"DailyJournal/#9162025","text":"Today, we learned about Git, Github, Github desktop, and the browser github as well. Specifically, we focused on how changes are stored in Git and the ability to create branches of the repo for development without affecting the original branch.","title":"9/16/2025"},{"location":"DailyJournal/#9172025","text":"Today, we practiced with Git and created shared Repo's with each other to practice with collaborator settings on github.","title":"9/17/2025"},{"location":"DailyJournal/#9242025","text":"Today, I decided to order the essential electronics for my project, this included the motor controllers, the batteries, and the safety mechanisms.","title":"9/24/2025"},{"location":"DailyJournal/#9252025","text":"Today, we did a soldering activity where we practiced surface mount and through hole soldering using a halloween owl kit which lights up when you touch it. The surface mount soldering, internal components, and the finished product are shown in pictures below.","title":"9/25/2025"},{"location":"DailyJournal/#9262025","text":"Outside of class today, I used the AI Claude with the Opus4.1 model to generate some starting code for my project. The programs I had made were a RP2040 Seeed program which will control the motors, and a RaspberryPi + AI Camera program which will hand the tracking aspects and math of the camera. I am using the AI formulated code as a launchpad in order to be more efficient and spend more time on customization and troubleshooting, than have to spend that time on writing the base code myself. However, to ensure I understood the code and would be able to edit and modify it, I made sure to go through each line and ensure that I understood why and what the line did, and how modifing that line of code would impact the overall preformance of the program. The initial prompts I inputed are shown below.","title":"9/26/2025"},{"location":"DailyJournal/#prompt-for-rp2040-seeed-code","text":"write me an arduino code for a RP2040 Seeed which will take input from the usb serial coming off a raspberry pi and move 2 drive motors on my robot using pwm(like how servos are controlled) according to the directions. For input directions, there should be a heading which if is outside the middle range set by me in a variable, then the program should turn until the the heading is once again within acceptable values. Another input will be the distance from the target which also should be kept within acceptable range set by me in a variable. Lastly, have a serial monitor where I can input values for left motor and right motors to test if I want. One last thing is whenever motor powers are set, send back what has been set across the usb serial for the Pi to recieve.","title":"Prompt for RP2040 Seeed Code"},{"location":"DailyJournal/#prompt-for-raspberry-pi-code","text":"can you now right me a raspberry pi program in pythong prob. that will provide these inputs needed based off a raspberry pi 5 and a raspberry pi AI camera attachment. Also have the raspberry pi host a webserver that allows the user to see the motor power assignements and camera feed. there should be a simple but neat UI for that web page pls.","title":"Prompt for Raspberry Pi Code"},{"location":"DailyJournal/#1062025","text":"I have done some thinking and realized that I was going too big on the first code attempt, so I backtracked a bit back to the Raspberry Pi AI Camera Documentation, and completed the instructions as well as ran the example program: rpicam-hello -t 0s --post-process-file /usr/share/rpi-camera-assets/imx500_mobilenet_ssd.json --viewfinder-width 1920 --viewfinder-height 1080 --framerate 30 This program worked amazing and highlighted me with a bounding box as well as providing a percentage of certanty which seemed to stay above 50% consistantly.","title":"10/6/2025"},{"location":"DailyJournal/#1072025","text":"","title":"10/7/2025"},{"location":"DailyJournal/#layouts","text":"Today, I worked on the electrical for the robot, mainly trying to get power and control to 1 motor for testing. The layout of main power in my electrical testing setup went as such: Battery(12v 15000AmH) --> Breaker(30A) --> MotorController(Koors40 Brushed DC Motor Controller) --> Motor(CIM Motor) Then, I had to have a seperate control setup which would tell the motor controller how to move the motor. I also had to wire up a 5V power source into the receiver because the PWM output from the motor controller didn't provide a 5V port, just signal and ground wires. The layout of the control setup went as such: Controller(Wireless RC Plane Controller) --> Reciever(RC Plane Reciever) --> MotorControllerPWM(Koors40 Brushed DC Motor Controller) I haven't built this part yet because I chose to focus on the main power layout.","title":"Layouts"},{"location":"DailyJournal/#making-connections","text":"The main focus I had when setting up the hardware was modularity. I want to be able to replace components if I need to, or swap them out wihtout having to unsolder or cut wires, so I decided to use Wago connectors which take to unsoldered raw wire ends, and clamp down a metal plate on the wires forming a connection between the wires on both sides. These connectors worked great, but I sadly only snagged 2 from my robotics team, and I inevitablly ended up needing 4, so I put the final wiring on hold until I could get some more Wago connectors. I also had to do some soldering to","title":"Making Connections"},{"location":"DailyJournal/#1082025","text":"Today, I found the github repo for the rpicam-hello program and ran it as a python file which allowed me to make edits to the code itself. I then used the AI ChatGPT from OpenAI to add in code for outputing where the human is in the serial terminal. I chose to use ChatGPT because Claude didn't seem great at modifing the codes without re-writing everything and that would always end up casuing errors. ChatGPT had me edit one of the functions and everything else stayed the same so when I tested the new code, it worked great and I was able to route the output to my computer terminal temporarily, so I could see the output without another device on the other side of the serial connection. Here is the original code: rpicam-hello Here is the updated code which I developed with AI assistance: modified rpicam-hello This code worked amazing and had very simular functions to the example, but a few key modifications to make it more effective and accurate for my use: - Added a stabalizing function - The data would update every frame and the bounding box would move after every update, still correct, but I don't need that much precision of 5 pixel shift to the left or whatever, so I insterted a snipet of code which only changes the detection bounding box if the center point has moved by >25 pixels, or the size has changed by 20%. This helped smooth the detection and give a more stable instruction which will be easier for the robot to follow. Added output to Serial for the Seeed board to receive instructions In order to tell the Seeed board where the person is, I outputed a formated set of data which gives the centerpoint x and y position, as well as the width and height of the bounding box. The format goes like such: x,y,w,l By changing the serial port from 3 to 1, which is the computers port, I was able to visualize the output on the terminal and confirm that the code was working correctly.","title":"10/8/2025"},{"location":"DailyJournal/#video-of-the-code-functioning","text":"","title":"Video of the Code Functioning"},{"location":"DailyJournal/#1092025","text":"Today, I continued working on the electrical testing setup I started on 10/7/2025. I acquired 4 more Wago connectors from my robotics team and finished up the connections between the motor and the motor controller using them. After finishing the main power setup, I started building the control wiring setup. I used a 5V power supply to power a remote control plane reciever which outputs a pwm signal, used to control the motor. Then I attached the pwm signal and ground to the reciever on the throttle port of the reciever and was able to control the motor using a RC Plane Remote.","title":"10/9/2025"},{"location":"DailyJournal/#video-of-motor-moving","text":"","title":"Video of motor moving"},{"location":"ProjectOverview/","text":"Goals I have been working on the brainstorming and planning for this project for over half a year, and these are the realistic goals I have set for myself in order to consider this porject a success. Basic Build Goals Build a Modular Mounting Frame that will allow customizability and adaptabiltity Build a gearbox that can be mounted on frame to drive wheels Be able to hold a backpack Be able to drive around Not too pricey Robust and Durable even in bad weather conditions Look Amazing! Basic Programming/Hardware Goals Modular Programming setup as well for future project use and easy transport of code testing materials Track and follow a human in front of the robot Assign powers to the wheels according to the tracking data and make the robot follow the user Clean and Organized Code! Advanced Goals Instead of following a user, the robot understands it's surroundings and can navigate itself to a selected location Selected location can be chosen through voice commands Robot can detect obstacles and chose to avoid or simply stop and wait. Robot can connect to a server where robot data on location, travel, speed, battery, etc. can be accesed and this could potentially lead to mutliple RoboPack units collaborating. Design Specification Considerations What do you want your project to do? a backpack carrying robot I have named the \"Robopack\". This robot will carry around your backpack for you and will give me a starting point for future more intricate and advanced projects. Is the project for you or someone else? For me initially, but potentially adverstisable to the school as autonomous helper units. If someone else, have you talked to them about design specs? I have talked a bit to an electrician I know about the electronics of the project Are you considering a group project? What is your part Not really, but if someone wanted to join me and add on to the project, I would be open to collaborators. Will your project be inside or outside? Mostly outside but a bit of both. Will your project be portable? Yes, the robot needs to be somewhat portable Will your project connect to the Internet? Yes, it will interact with image vision proccesing and speak to a main base computer Will your project use Bluetooth? Probably not but it could if I connect phone integration. Does your project use a vinyl cutter? Yes, for branding and warning stickers. Does your project use a laser cutter? Yes, for initial gearbox prototypes Does your project use a 3D printer? Yes, for the wheels and additional complex 3Dparts Does your project use a large CNC machine (Shopbot)? Yes for the expensive wood cutting, but also the small for cutting aluminium for the final gearbox plates Does your project have intelligence (Arduino, Raspberry Pi, computer)? Yes, a raspberry pi for computing the vision proccesing and communicating back to a home base computer What are your project inputs? Camera, Microphone, Switches like breakers and safeties. What are your project outputs? Motors, Speaker How does your project differ from the project that inspired you? The project that inspired me was the starships but my project will hold backpacks instead of food and provide a base for many more applications in the future rather than limiting the functionality to one aspect. When was the inspirational project built? July 3rd, 2014 was when starships took off. Do you have a tutorial or instructions for your project? No, I will be taking on the challenge from scratch. How current is the tutorial? Does not exist currently. What is the maximum that you want to spend? No more than $75.00 $450, but I will be paying out of pocket as this is a passion project for me. What are the dimensions of your project? 24\"x20\"x15\" Frame and then some bottom ~6\" for the motor + wheels What materials will you use? 80/20 Framing, CIM Motors, Raspberry Pi, and more that are undetermined as of now. Have you completed the spreadsheet? No? I have a rough BOM spreadsheet currently. Are the parts for your project still available? Yes, I have a lot of them accesable to me for free or already have them Are the tools you need for the project found in the FabLab? Some yes, and some are found in my robotics location. How will you conceal the electronics? Using a removable pannel on the bottom of the robot.","title":"Project Overview"},{"location":"ProjectOverview/#goals","text":"I have been working on the brainstorming and planning for this project for over half a year, and these are the realistic goals I have set for myself in order to consider this porject a success.","title":"Goals"},{"location":"ProjectOverview/#basic-build-goals","text":"Build a Modular Mounting Frame that will allow customizability and adaptabiltity Build a gearbox that can be mounted on frame to drive wheels Be able to hold a backpack Be able to drive around Not too pricey Robust and Durable even in bad weather conditions Look Amazing!","title":"Basic Build Goals"},{"location":"ProjectOverview/#basic-programminghardware-goals","text":"Modular Programming setup as well for future project use and easy transport of code testing materials Track and follow a human in front of the robot Assign powers to the wheels according to the tracking data and make the robot follow the user Clean and Organized Code!","title":"Basic Programming/Hardware Goals"},{"location":"ProjectOverview/#advanced-goals","text":"Instead of following a user, the robot understands it's surroundings and can navigate itself to a selected location Selected location can be chosen through voice commands Robot can detect obstacles and chose to avoid or simply stop and wait. Robot can connect to a server where robot data on location, travel, speed, battery, etc. can be accesed and this could potentially lead to mutliple RoboPack units collaborating.","title":"Advanced Goals"},{"location":"ProjectOverview/#design-specification-considerations","text":"What do you want your project to do? a backpack carrying robot I have named the \"Robopack\". This robot will carry around your backpack for you and will give me a starting point for future more intricate and advanced projects. Is the project for you or someone else? For me initially, but potentially adverstisable to the school as autonomous helper units. If someone else, have you talked to them about design specs? I have talked a bit to an electrician I know about the electronics of the project Are you considering a group project? What is your part Not really, but if someone wanted to join me and add on to the project, I would be open to collaborators. Will your project be inside or outside? Mostly outside but a bit of both. Will your project be portable? Yes, the robot needs to be somewhat portable Will your project connect to the Internet? Yes, it will interact with image vision proccesing and speak to a main base computer Will your project use Bluetooth? Probably not but it could if I connect phone integration. Does your project use a vinyl cutter? Yes, for branding and warning stickers. Does your project use a laser cutter? Yes, for initial gearbox prototypes Does your project use a 3D printer? Yes, for the wheels and additional complex 3Dparts Does your project use a large CNC machine (Shopbot)? Yes for the expensive wood cutting, but also the small for cutting aluminium for the final gearbox plates Does your project have intelligence (Arduino, Raspberry Pi, computer)? Yes, a raspberry pi for computing the vision proccesing and communicating back to a home base computer What are your project inputs? Camera, Microphone, Switches like breakers and safeties. What are your project outputs? Motors, Speaker How does your project differ from the project that inspired you? The project that inspired me was the starships but my project will hold backpacks instead of food and provide a base for many more applications in the future rather than limiting the functionality to one aspect. When was the inspirational project built? July 3rd, 2014 was when starships took off. Do you have a tutorial or instructions for your project? No, I will be taking on the challenge from scratch. How current is the tutorial? Does not exist currently. What is the maximum that you want to spend? No more than $75.00 $450, but I will be paying out of pocket as this is a passion project for me. What are the dimensions of your project? 24\"x20\"x15\" Frame and then some bottom ~6\" for the motor + wheels What materials will you use? 80/20 Framing, CIM Motors, Raspberry Pi, and more that are undetermined as of now. Have you completed the spreadsheet? No? I have a rough BOM spreadsheet currently. Are the parts for your project still available? Yes, I have a lot of them accesable to me for free or already have them Are the tools you need for the project found in the FabLab? Some yes, and some are found in my robotics location. How will you conceal the electronics? Using a removable pannel on the bottom of the robot.","title":"Design Specification Considerations"},{"location":"RobotJourney/","text":"Mechanical Systems I started my CAD journey a while back in sophmore year as I was super exited for this project, but I will do my best to re-track my steps to show how the CAD came to be. I started off my design by drawing out what I wanted the robot to look like, what parts I could use, etc. At the start, I was thinking about using 2x4 wooden board due to them being cheep, accesible, and sturdy. However, I decided to use 80/20 due to it's modularity and robustness Programming Systems I started off the coding of the Raspberry Pi Brain by installing the Raspberry Pi AI Camera and followed the instructions from the Raspberry Pi AI Camera Documentation . After setting up the IMX 500 Library, I ran the example object dection code with the following terminal command: rpicam-hello -t 0s --post-process-file /usr/share/rpi-camera-assets/imx500_mobilenet_ssd.json --viewfinder-width 1920 --viewfinder-height 1080 --framerate 30 This program outputed the live camera feed and projected a bounding box over any detected objects with the object type and certanty. From my testing, I determined that this model would work best for my project because unlike some other models I tested like YOLTOV, which would sometimes not identify humans if they were too close or did sudden movements, this test program almost always had a >50% certanty in identifying me as a person when I was within 5 feet of the camera lense even if I jumped or moved rapidly. My next step in developing my control program for the RoboPack was to combine the knowledge of AI, with the example object detection code, to get a simple program that's goal is to use the example code and add in the logic to give motor control instructions to a seperate board. Hardware Systems In order to ensure that my project was feasable and that I would be able to control the level of motors which I desired, I started off by creating a large Bill Of Materials with everything I would need","title":"Robot Journey"},{"location":"RobotJourney/#mechanical-systems","text":"I started my CAD journey a while back in sophmore year as I was super exited for this project, but I will do my best to re-track my steps to show how the CAD came to be. I started off my design by drawing out what I wanted the robot to look like, what parts I could use, etc. At the start, I was thinking about using 2x4 wooden board due to them being cheep, accesible, and sturdy. However, I decided to use 80/20 due to it's modularity and robustness","title":"Mechanical Systems"},{"location":"RobotJourney/#programming-systems","text":"I started off the coding of the Raspberry Pi Brain by installing the Raspberry Pi AI Camera and followed the instructions from the Raspberry Pi AI Camera Documentation . After setting up the IMX 500 Library, I ran the example object dection code with the following terminal command: rpicam-hello -t 0s --post-process-file /usr/share/rpi-camera-assets/imx500_mobilenet_ssd.json --viewfinder-width 1920 --viewfinder-height 1080 --framerate 30 This program outputed the live camera feed and projected a bounding box over any detected objects with the object type and certanty. From my testing, I determined that this model would work best for my project because unlike some other models I tested like YOLTOV, which would sometimes not identify humans if they were too close or did sudden movements, this test program almost always had a >50% certanty in identifying me as a person when I was within 5 feet of the camera lense even if I jumped or moved rapidly. My next step in developing my control program for the RoboPack was to combine the knowledge of AI, with the example object detection code, to get a simple program that's goal is to use the example code and add in the logic to give motor control instructions to a seperate board.","title":"Programming Systems"},{"location":"RobotJourney/#hardware-systems","text":"In order to ensure that my project was feasable and that I would be able to control the level of motors which I desired, I started off by creating a large Bill Of Materials with everything I would need","title":"Hardware Systems"},{"location":"RobotPlanning/","text":"Mechanical Planning Frame Planning I started off my mechanical planning for the RoboPack by thinking about the frame of the robot. From my previous robotics experience, I have learned that modularity and the ability to re-use and adjust is essential. To ensure optimal flexability, I chose to use 80/20 tubing, specifically the 1530 & 1515 series tubing shown below for robust structure, flexible attachment points, and premade strong brackets that can be re-used and moved. 1530 Tubing 15Series Bracket Style Planning After getting all the functionality down, I plan to use a nice wood to give a natural style to the robot. Another idea I have is to get plastic parts that can cover the machine as well, but that might be more complicated and expensive. Hardware Planning Motors & Motor Controller I am planning to use CIM motors which I've learned from my robotics teams, the reason for using a CIM motor is due to low costs sitting at around 17$, and the output it produces being 5,330 RPM, with 21.33 in/lbs of torque which is pretty powerfull and should definatly ensure a job well done. Software Planning","title":"Robot Planning"},{"location":"RobotPlanning/#mechanical-planning","text":"","title":"Mechanical Planning"},{"location":"RobotPlanning/#frame-planning","text":"I started off my mechanical planning for the RoboPack by thinking about the frame of the robot. From my previous robotics experience, I have learned that modularity and the ability to re-use and adjust is essential. To ensure optimal flexability, I chose to use 80/20 tubing, specifically the 1530 & 1515 series tubing shown below for robust structure, flexible attachment points, and premade strong brackets that can be re-used and moved. 1530 Tubing 15Series Bracket","title":"Frame Planning"},{"location":"RobotPlanning/#style-planning","text":"After getting all the functionality down, I plan to use a nice wood to give a natural style to the robot. Another idea I have is to get plastic parts that can cover the machine as well, but that might be more complicated and expensive.","title":"Style Planning"},{"location":"RobotPlanning/#hardware-planning","text":"","title":"Hardware Planning"},{"location":"RobotPlanning/#motors-motor-controller","text":"I am planning to use CIM motors which I've learned from my robotics teams, the reason for using a CIM motor is due to low costs sitting at around 17$, and the output it produces being 5,330 RPM, with 21.33 in/lbs of torque which is pretty powerfull and should definatly ensure a job well done.","title":"Motors &amp; Motor Controller"},{"location":"RobotPlanning/#software-planning","text":"","title":"Software Planning"}]}